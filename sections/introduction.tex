\section{Introduction}\label{sec:introduction}
One of the most promising approaches for fault-tolerant quantum computation is based on surface quantum error correcting codes \cite{dennis2002topological, kitaev2003fault}. With surface codes, error correction only requires the measurement of local operators on a 2-dimensional lattice of qubits. The measurement outcome, called the syndrome, is passed to the decoding algorithm to deduct the error that has occurred and to supply a correction operator. The resilience against errors can be improved by increasing the system size whilst the physical error rate is below a threshold value $p_{th}$. For this, it is essential that the decoder has low time complexity; if the clock-rate of the quantum computer becomes limited by the decoder, the advantages of increasing the system size could be compromised.

Arguably, the most popular decoder for surface codes is the Minimum-Weight Perfect Matching (MWPM) decoder \cite{dennis2002topological}. The basic principle behind this approach is to identify the \emph{lowest weight} error configuration that can produce the syndrome. In general this is a good approximation to the optimal maximum likelihood decoder \cite{bravyi2014efficient}. For a toric code that only suffers random Pauli noise, the optimal code threshold is $p_{th} = 10.9\%$, whereas the MWPM decoder has $p_{th} = 10.3\%$. The minimum-weight matchings are found by constructing a fully connected graph between nodes of the syndrome, which leads to a cubic worst-case time complexity of $\mathcal{O}(n^3)$, where $n$ is the number of qubits in the system \cite{kolmogorov2009blossom}. Fowler has proved that the matching problem can be solved in average$\mathcal{O}(1)$ time, but only at sufficiently low error rates, and the worst-case complexity remains significant \cite{fowler2013minimum}. 

Many other decoding algorithms have been developed \cites{duclos2013fault, hutter2015improved, watson2015fast, tuckett2018ultrahigh, kubica2019cellular, torlai2017neural, varsamopoulos2017decoding}. Here, we build on top of a recently proposed decoder called the Union-Find (UF) decoder. It combines a very low time complexity with a high threshold \cite{delfosse2017linear, delfosse2017almost} making it a practical solution for real devices. 
The UF decoder maps each syndrome to a vertex in a non-connected graph on the code lattice, and grows clusters of vertices locally by adding iteratively a layer of edges and vertices to existing clusters until all clusters have an even number of non-trivial syndrome vertices. It then trims the clusters until all non-trivial syndrome vertices are paired and linked by a path, which is the correcting operator. By growing the clusters of vertices in order of their sizes, the UF-decoder can be regarded as a heuristic for minimum-weight matching, and has a threshold of $p_{th} = 9.9\%$ for the toric code. The complexity of the UF decoder is driven by the merging between clusters. For this the algorithm uses the Union-Find or disjoint-set data structure \cite{tarjan1975efficiency}, which has worst-cast time complexity $\mathcal{O}(n\alpha(n))$, where $\alpha$ is the inverse of Ackermann's function. For any physical feasible amount of qubits, this value is $\alpha(n) \leq 3$, leading to an ``almost-linear'' time complexity.

We propose here a modification of the UF decoder that improves the heuristic for minimum-weight matching. The modified decoder, which we dub the \emph{Union-Find Balanced Bloom decoder} (UFBB), achieves near MWPM thresholds while retaining a quasilinear time complexity. In section \ref{sec:surfacecode} we introduce the surface code. In sections \ref{sec:matchingweight} and \ref{sec:ufbb} we describe the modified algorithm and its motivation. We discuss the complexity of the algorithm in section \ref{sec:complexity} and compare its performance with other decoders in section \ref{sec:performance}.  