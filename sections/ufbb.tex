\section{Union-Find Node-Suspension decoder}\label{sec:ufbb}

In this section, we describe the \emph{Union-Find Node-Suspension} decoder, that increases the Union-Find decoder's performance by improving its heuristic for minimum-weight matching. We first introduce the concept of the potential matching weight in \ref{sec:matchingweight}. We describe the data structure required for this decoder in \ref{sec:nodeset}, and the necessary calculations performed on this data structure in \ref{sec:paritydelaysus}, \ref{sec:nodejoin} and \ref{sec:inversion}. The pseudocode is included in \ref{sec:pseudocode}. 

\Figure[htb](topskip=0pt, botskip=0pt, midskip=0pt){tikzfigs/tikz-figure0.pdf}{A cluster of vertices $\vset=\{v_0, v_1, v_2\}$ with potential matching weights $\{2, 3, 2\}$. The line style and color of the colored edges correspond to the matching in the hypothetical union with an external vertex $v'$ of the same line style and color.\label{fig0}}

\subsection{Potential matching weight}\label{sec:matchingweight}
%In the following we give some intuition into the improvement of the Union-Find Balanced Bloom decoder upon the original Union-Find decoder. 
% We compared the ratio of the matchings between the MWPM decoder and our own implementation of the UF decoder, averaged over many simulations, and found that UF matching weight has a constant prefactor of $\sim 1.043$ over the minimum weight for the toric code (Figure \ref{comp_weight}). From this, we suspected that a decreased matching weight is a heuristic for an increased threshold. Within the context of the UF decoder, the matching weight may be decreased by prioritizing the growth of vertices with low PWM's within the cluster. 

Consider the cluster with index $i$ containing the set of non-trivial vertices $V_i=\{v_0,v_1,v_2\}$ and set of edges $E_i=\{(v_0,v_1), (v_1, v_2)\}$ of Figure \ref{fig0}. Now let us investigate the weight of a matching if an additional non-trivial vertex $v'$ is connected to the cluster. If $v'$ is connected to $v_0$ or to $v_2$, then the resulting matching has a total weight of 2: $(v',v_0)$ and $(v_1,v_2)$, or $(v_0,v_1)$ and $(v_2,v')$. However, if $v'$ is connected to vertex $v_2$, then the total weight is 3: $(v', v_1)$ and $(v_0, v_2)$. Inspired by this idea, we introduce the concept of potential matching weight (PMW) of a vertex. 

\begin{definition}\label{def:pmw}
    % For, the hypothetical merger with another odd-parity cluster $V_j, E_j$ on the edge $(v_i, v_j)$, with $v_i\in V_i$ and  $v_j \in V_j$, outputs an even-parity cluster with edges $E_{ij} = E_i \cup E_j \cup (v_i, v_j)$ in which there exists a matching $\m{C}_{(v,v')} \subseteq E_{ij}$ between syndromes internal to the cluster.
    Let the Potential Matching Weight (PMW) of vertex $v_\alpha \in V_\alpha$ in an odd-parity cluster $\alpha$ with vertices $V_\alpha$ and edges $E_\alpha$ be
    \begin{equation}
      PMW(v_\alpha) = \abs{\m{C}_{(v_\alpha,v_\beta)} \cap E_\alpha} + 1,
    \end{equation}
    where matching $\m{C}_{(v,v')} \subseteq E_{ij}$ is between the syndrome vertices internal to the even-parity cluster with edges $E_{ij} = E_\alpha \cup E_\beta \cup (v_\alpha, v_\beta)$, after a hypothetical merger of cluster $\alpha$ with another odd-parity cluster $V_\beta, E_\beta$ on the edge $(v_\alpha, v_\beta)$, with $v_\alpha\in V_\alpha$ and  $v_\beta \in V_\beta$
\end{definition}

In other words, the PMW is a vertex-specific predictive heuristic to the matching weight assuming a union in the next growth iteration. The PMW can be utilized by prioritizing the growth of vertices with low PMW such that there is an increased probability of mergers between clusters on edges connected to these vertices, and an increased probability in a lower matching weight. However, the calculation of the PMW's within a cluster is not a trivial task, especially for clusters of increasingly larger size, as all edges of a cluster must be considered in its calculation. Furthermore, the PWM's within a cluster change due to cluster growth and mergers, both of which occuring more frequently as the system size is increased. The scaling of the PMW computation is for this reason vital to the decoder. 

\Figure[htb](topskip=0pt, botskip=0pt, midskip=0pt){tikzfigs/tikz-figure1.pdf}{The cluster of Figure \ref{fig0} after two round of prioritized growth of $v_0$ and $v_2$. There are regions of vertices that are either interior elements or have equal potential matching weights, which can be represented as nodes with different node radii in the node-tree $\nset$. \label{fig1}}

\subsection{Node-Suspension data structure}\label{sec:nodeset}

Fortunately, the PMW calculation is quite efficient by the introduction of a new data structure. Consider the cluster of non-trivial vertices $V_i=\{v_0,v_1,v_2\}$ and set of edges $E_i = \{(v_0,v_1), (v_1, v_2)\}$ from Figure \ref{fig0}. We had found previously that vertices $v_0, v_2$ have a lower PWM compared to $v_1$ by 1 edge. The growth of $v_0$ and $v_2$ are thus prioritized, such that new vertices are added to the cluster on the boundary of $v_0$ and $v_2$. If all newly added vertices are trivial, the cluster is now as depicted in Figure \ref{fig1}. If we repeat the PMW calculation, we now find that the PMW's in the new vertices connected to $v_0$ are equal, and the same is true for vertices connected to $v_2$. 
\begin{definition}
    Let the vertex-tree $\vset_i$ be the spanning tree of the graph of a cluster $G(V_i, E_i)$, a subgraph that is a tree which includes all vertices $V_i$ and a minimum number of edges in $E^\vset_i \subseteq E_i$. 
\end{definition}
\begin{definition}
  Let the node-tree $\nset_i$ be a partition of the vertex-tree $\vset_i$, such that each element of the partition --- a node $n$ --- consists of a set of adjacent vertices that lie within a certain distance - the node radius $nr$ - of the \textbf{prime vertex}, which lies at the center of the node. The edges $\m{E}_i$ of the node-tree have lengths equal to the distance between the prime vertices of neighboring nodes. 
\end{definition}

The concept of prime vertices is easily understood when considering non-trivial vertices of the syndrome $\sigma$. If every non-trivial vertex is the primer of a node, the weight of a matching in $\vset_i$ equal to the weight of the same matching in $\nset_i$. Within every node of the node-tree, all vertices that lie at distance $nr$ to the prime vertex are boundary vertices of the cluster, and have equal PMW. For the example in Figure \ref{fig1}, the PMW of $n_0$ is $\floor{nr_0} + (n_1, n_2) + 1$. The partition thus allows us to compute the PMW on a reduced tree. 

A node with a non-trivial vertex as its primer is called a \textbf{syndrome-node} $sn$. However, not all prime vertices are non-trivial vertices of the syndrome. If two non-trivial vertices are located an even manhattan-distance on the lattice, the growth of their clusters can simultaneously reach some vertex that lies on equal radii of the associated nodes, such as in Figure \ref{fig2}. For this reason, such vertices serve as primers of a different type of node --- a \textbf{junction-node} $jn$ --- in the merged node-tree. 

\Figure[htb](topskip=0pt, botskip=0pt, midskip=0pt){tikzfigs/tikz-figure2.pdf}{Two different types of nodes. Syndrome-nodes $sn$ have a non-trivial vertex or syndrome at its center. Vertices that lie on the radii of two existing nodes initialize a junction-node $jn$ in the node-tree.\label{fig2}}

The calculation of the PMW on the node-tree $\nset$ rather than the vertex-tree $\vset$ offers a reduction in the cost. However, it is still no trivial task as the entire tree must be considered for the calculation in each node. Instead, we will compute for the \textbf{node suspension} --- the number of growth iterations needed to reach the maximum PMW in the node-tree --- which relates closely to the PWM. For example, the node suspension for the nodes $\{n_0, n_1, n_2\}$ associated with the vertices $\{v_0, v_1, v_2\}$ in Figure \ref{fig0} is $\{0, 2, 0\}$ and $\{0, 1, 0\}$ in Figure \ref{fig1}.

Additionaly to the cluster-trees of distinct roots of the Union-Find data structure, we store for each cluster the node-tree $\nset_i$ by its root. For this, we need to maintain the reduced set of edges $E^\vset_i \subseteq E_i$ for every cluster, which can be done in constant time. In the UF decoder, vertex-trees $\m{V}_i$ are not maintained, such that the graph associated with each cluster is not acyclic \cite{delfosse2017almost}. But after growth, a spanning forest of all clusters is created \cite{delfosse2017linear}, which are acyclic connected graphs equivalent to vertex-trees $\vset_i$. Thus, the maintainance of the aclycic vertex-trees does not alter the protocol of the Union-Find decoder, and the Node-suspension data structure does not replace but coexists with the Union-Find data structure. 

\Figure[b](topskip=0pt, botskip=0pt, midskip=0pt){tikzfigs/tikz-figure3.pdf}{Two depth-first searches on $\mathcal{N}$ to compute node parities (head recursively) and delays (tail recursively).\label{fig3}}


\subsection{Node parity, delay and suspension}\label{sec:paritydelaysus}

The Node-Suspension data structure allows for the calculation of the node suspension of all nodes in a node-tree $\nset$ by two intermediate steps. In each step a depth-first-search (DFS) of $\nset$ is applied, such that the calculation can be performed in linear time to the node-tree dimension.

In the first DFS, we calculate for the \textbf{node parity} $np$ --- the number of descendant syndrome-nodes of a node modulo 2 --- via a tail recursive function, which is only dependent on the node parities of the children nodes of a node.
\begin{align}\label{eq:nodeparity}
    snp &= &\big( \sum_{\mathclap{n_\gamma \in \text{ children of } sn}} (1-np_\gamma) \big ) \bmod 2 \hspace{1em}  \\
    jnp &= 1 - &\big(\sum_{\mathclap{n_\gamma \in \text{ children of } jn}} (1-np_\gamma) \big) \bmod 2 \hspace{1em}
\end{align}

In the second DFS, we calculate for the difference in node suspension of a node $n_\beta$ with its parent $n_\alpha$; $\delta = ns_\beta - ns_\alpha$. We can choose an arbitrary \textbf{node delay} $nd$ --- the node suspension minus the maximum node suspension in the node-tree --- for the root node such as $nd_r=0$ and add the suspension difference $\delta$ during each step to obtain $nd$ for every node. This node delay of a node $n_\beta$ is only dependent on the node radii of itself and of its parent $n_\alpha$, the length of edge $(n_\beta, n_\alpha)$ and its parity $np_\beta$. 
\begin{multline}\label{eq:delayequation}
    nd_\beta = nd_\alpha + \Bigg \lceil 2k_{inv}\bigg(\ceil{nr_\beta} - \floor{nr_\alpha + nr_\beta \bmod 1}\\
    - (-1)^{np_\beta}\abs{(n_\beta,n_\alpha)}\bigg) - 2(nr_\beta - nr_\alpha) \bmod2 \Bigg \rceil
\end{multline}
Here, the \textbf{inversion factor} $k_{inv}$ is a constant that deals with the inversion of node parities in a node-tree during merges of clusters, explained in \ref{sec:nodejoin}. 

There is a final step in calculating the node suspension from the node delay, which are related by
\begin{equation}\label{eq:suspension}
    ns = nd - \max_{nd_i \in \nset} nd_i - nw, 
\end{equation}
where $nw$ is equal to the number of iterations a node has \textbf{waited} or has been suspended from growth. The maximum node delay can be maintained during the second DFS of the node-tree, and the node suspension itself is calculated during the DFS related to the growth of the cluster, such that this step is not counted towards the node suspension calculation. 

\Figure[htb](topskip=0pt, botskip=0pt, midskip=0pt){tikzfigs/tikz-figure4.pdf}{
    (a) An odd cluster $\nset^o=\{n_1, n_2, n_o\}$ with root $n_1$ joins with an even cluster $\nset^e=\{n_3, n_e\}$ with root $n^e_r=n_3$ on nodes $n_o, n_e$, respectively, to a joined node-tree. If we choose to (b), make $n_e$ a child of $n_o$, the parities and delays the sub-tree of $\nset^o$ can unchanged, and we only have to perform partial parity and delay calculations over the sub-tree of $\nset^e$. If we choose to (c), make $n_o$ a child of $n_e$, parities and delays have to be recalculated in the entire joined node-tree. \label{fig4}}

A single growth iteration, which is applied in the original UF decoder by adding half-edges to all boundary vertices of the cluster, is now replaced by another DFS of $\nset$. During this DFS, a node is conditionally grown -- adding half-edges to the boundary vertices in the current node and adding 1 to its radius $nr$ -- if $ns$ is equal to zero. If not, suspend the node growth, add 1 to $nw$ and continue with the DFS. A subsequent growth iteration now does not require the two DFS's related to the calculation of $np$ and $nd$, provided that no union between clusters has occurred. Hence, the Node-Suspension data structure enables us to calculate the node suspension across multiple growth iterations based on a single calculation of the node parity and delay. When all $ns$ in $\nset$ are zero, all nodes are bloomed simultanenously within the same iteration. 

Note that we hadn't stated which node in $\nset$ should be the root node. In fact, any node in $\nset$ could have been picked as the root of the node-tree. This property, together with the constancy of $np$ and $nd$ in between cluster unions, allows us to define a set of rules for the merging of node-trees.  


\subsection{Joining node-trees}\label{sec:nodejoin}

In the Union-Find algorithm, clusters of an odd number of non-trivial vertices or elements of $\sigma$ grow in size repetitively and merge with other clusters until all clusters are of even parity. During this process, the node-trees of the Node-Suspension data structure must also be merged. Let us now first make a clear distinction between the merging protocols of the underlying data structures; the vertex-trees of the UF data structure are merged with \codefunc{Union}, whereas the node-trees are merged with \codefunc{Join}. After a join of multiple node-trees, the node suspensions within the combined node-tree change. The focus of the \codefunc{Join} protocol is therefore to minimize the DFS's of the recalculation of the node parity and delays in the combined node-tree. 

First, note that as a cluster of even parity has an even number of non-trivial vertices, its node-tree has an even number of syndrome-nodes. The concept of PMW does not exist for an even node-tree as the matching can be made within the node-tree. Consequently, node suspension, parity and delays are undefined for an even node-tree. 
%Thus, if two odd clusters merge into an even cluster, we don't know and do not care about its node suspensions. 

A second type of merge is the between an even and an odd cluster. The combined cluster is odd and its growth must be continued, thus its node suspensions must be computed. Now, consider the example of odd node-tree $\nset_o$ and even node-tree $\nset_e$ that are to be joined on nodes $n_o\in \nset_o$ and $n_e \in \nset_e$ (Figure \ref{fig4}\emph{a}). If the root of $\nset_o$ is kept as the root of the joined node-tree (Figure \ref{fig4}\emph{b}), $n_e$ is to be a child node of $n_o$. As $\nset_e$ contains an even number of syndrome-nodes, the node parities in $\nset_e$ do not change. Hence, the DFS of the node parity recalculation is only necessary in the sub-tree of $\nset_e$, which now has $n_e$ as sub-root. Furthermore, as the node delay is only dependent on the properties of a node and of its parent node, the DFS of the node delay recalculation is also only required from node $n_e$ and is performed within the sub-tree of $\nset_e$. These partial DFS's of the node-tree are exactly what was required as the node parity and delays in $\nset_e$ were undefined. If the root of $\nset_e$ takes the role of the root of the combined tree (Figure \ref{fig4}\emph{c}), an odd number of syndrome-nodes are attached to $n_e$, such that the parities of nodes on the path from $n_e$ to the root are changed. Such a join would require the DFS's for the entire combined node-tree of the recalculation of node parities and delays. A simple rules is thus to always keep the root of the odd node-tree. 

Finally, a cluster can be subjected to mergers with multiple other clusters within the same growth iteration, during which the merged cluster may switch parity multiple times. The DFS's related to the recalculation of the node parities and delay must for this reason not be initiated directly after the joining of node-trees. Instead, a pointer to the sub-root of the even sub-tree in the most recent odd-even join is stored at the root of the node-tree. The recalculation from the sub-root is then initiated just before cluster growth to prevent multiple recalculations over the same partitions of the node-tree. 


\subsection{Parity inversion}\label{sec:inversion}

An unfortunate effect of the Node-Suspension data structure, which we dub \textbf{parity inversion}, causes a decrease in the performance of the algorithm as the lattice size is increased (see Figure \ref{threshold_ufbb}). We will demonstrate this effect through the example in Figure \ref{fig5}\emph{a}. Consider three instances of the node-tree of Figure \ref{fig0}; $\nset_a, \nset_b, \nset_c$, positioned closely to each other on the lattice. Every node in all node-trees have radius $\nicefrac{1}{2}$, and the node suspension in $n_1$ in each node-tree is 2. This means that if $n_1$ is suspended for two growth iterations, such as in Figure \ref{fig1}, all nodes have the same PMW. However, in the current example, the node-trees $\nset_a, \nset_b, \nset_c$ merge after 1 iteration. The merged cluster is odd, thus we recalculate the node parities and delays to find that the parities in the partition of the node-tree containing the nodes of $\nset_b$ have been inverted, and the node suspensions in this partition have increased dramatically. If the next merging event occurs on the node with the increased node suspension, the matching weight may be larger compared to the original UF decoder, which defies the current goal. 

\Figure[t!](topskip=0pt, botskip=0pt, midskip=0pt){tikzfigs/tikz-figure5.pdf}{
    The node suspension values for nodes for 3 odd node-trees $\{\nset_1, \nset_2, \nset_3\}$ of 3 nodes that grow and join into a single node-tree. (a)
    Node suspensions are calculated by setting $k_{inv}=1$ in equation \eqref{eq:delayequation}. In step 1, the growth in the outer nodes of each of the three node-trees are prioritized and the node-trees merge. In step 2, recalculation of the joined node-tree isperformed. Parities within the sub-tree of $\nset_2$ are now inverted, and the suspension in these nodes have doubled. (b) Node suspensions are calculated by setting $k_{inv}=\nicefrac{1}{2}$. Now the increase in node suspensions after parity inversion is halved.\label{fig5}}

This defines a trade-off in the node suspension; a node must wait as many iterations as it is suspended to reach equal PMW in the node-tree, but after a parity-inversion the node suspension for previously prioritized nodes increase linearly with the number of iterations waited by the suspended nodes pre-inversion. As a compromise, we redefine the node suspension as \textbf{half} the number of growth iterations needed for all nodes in the node-tree to reach equal PMW. This can be done in Equation \eqref{eq:delayequation} by setting $k_{inv}=0.5$.

Nevertheless, as more parity inversions occur, the maximum node suspension in the node-tree increases, and it becomes more and more unlikely for a cluster to actually reach zero node suspension in all nodes. The number of parity inversions is directly related to the number of merging events, and thus the size of the lattice. The performance to improve the heuristic for minimum weight matchings thus decreases for larger lattices. 

