\section{Union-Find Balanced-Bloom decoder}\label{sec:ufbb}

\section{Node-tree data structure of clusters}\label{sec:nodeset}

To efficiently calculate the potential matching weights in a cluster, we introduce here an additional data structure, the \emph{node-tree} of a cluster, that coexists with the Union-Find data structure. We consider the case of independent noise. After syndrome identification, all identified clusters consist of a single syndrome-vertex $v_\sigma \in \sigma$. Note that with erasure noise, the initially identified clusters may be of larger size, where each connected graph of erased edges belonging to the same cluster. This set of clusters is equivalent to the syndrome set $\sigma$. Within syndrome validation, these clusters are subjected to growth and merge events with other clusters. During growth, all vertices added to some cluster $c_j$ have some closest syndrome vertex $v_\sigma$ within $c_j$ in the syndrome set $\sigma$, if a dynamic tree of the cluster is maintained. Recall from section \ref{sec:dynamicforest} that a such a cluster is always a connected acyclic graph. Even after cluster merges, newly added vertices have some closely located syndrome-vertex. The growth of a cluster can thus be interpreted to be \emph{seeded} in the syndrome vertices $v_\sigma \in \sigma$. Thus, the growth of a single cluster containing multiple syndrome vertices is related to multiple seeded growths. 

\begin{theorem}\label{the:nodepmw}
  All vertices in the subset of boundary vertices seeded in the same syndrome-vertex, $ \{v_1, v_2,...\}_{v_\sigma}$, have the same potential matching weight if a dynamic forest is maintained. 
\end{theorem}
\begin{proof}
  All vertices $v_i \in \{v_1, v_2,...\}_{v_\sigma} \subseteq \delta\vset_j$ of an odd-parity cluster $c_j$ have the same syndrome-vertex $v_\sigma$, which is located at minimum distance $d_i = |(v_i, v_\sigma)|$ on a path supported by edges in $\m{E}_j$. As a growth iteration means to grow all boundaries, all distances $d_i$ have the same value. A hypothetical matching $\m{C}$ with another odd-parity cluster on vertex $v_i$ must contain edges $(v_i, v_\sigma)$ since $c_j$ is a tree. Furthermore, $\m{E}_j\cap (\m{C} \setminus (v_i, v_\sigma))$ is independent of which vertex $v_i$ as long as they have the same seed. Thus, the potential matching weight
  \begin{equation}
    PMW(v_i) = \abs{(v_i, v_\sigma)} + \abs{\m{E_j}\cap (\m{C} \setminus (v_i, v_\sigma))} = \text{ constant } \forall v_i \in \{v_1, v_2,...\}_{v_\sigma}. 
  \end{equation}
\end{proof}

\begin{definition}\label{def:node}
  Let a node $nn$ represent a subset of vertices of a cluster for which each vertex is seeded in the same seed vertex $v_{seed}$, which is denoted as $n.\vset$ in object notation. 
\end{definition}

\begin{definition}\label{def:nodeset}
  Let a cluster $c_j$ also be represented by a \emph{node-set} $snodeset_j = \{n_1, n_2, ...\}$, stored as a tree by its root node at the cluster $c.n_r$. The subset of $n_i.\vset$ containing vertices in the boundary $\delta\vset_j$ is denoted $n_i.\delta\vset$, where $\delta\vset_j \supseteq n_i.\delta\vset \subseteq n_i.\vset$. Let the combined set of all nodes on a graph be denoted as $\nset$.
\end{definition}

Per Theorem \ref{the:nodepmw} and Definition \ref{def:nodeset}, all boundary vertices of a node have the same potential matching weight. The calculation of the potential matching weights within a cluster can thus be limited to its node-tree $\nset_j$. From our previous example, each vertex in cluster $c_e$ is a syndrome-vertex. For each of the vertices, their seed syndrome vertices are themselves. The node-tree is thus $\nset_e = \{n_1, n_2, n_3\}$ where $v_1 \in n_1.\vset$, $v_2 \in n_2.\vset$, and $v_3 \in n_3.\vset$. As this cluster grows in size, the number of vertices in $\vset_e$ increases in each round, while the number of nodes in $\nset_e$ remains the same at three nodes (Figure \ref{fig:nodesetpmw}). The node-tree is thus a \emph{reduced tree} of cluster $c_i$ where each node contains a subset of vertices in $\vset_j$, and each edge of the \emph{reduced tree} is equivalent to one or more edges in $\m{E}_j$. Furthermore, as every node needs to be seeded in some vertex, the number of nodes $|\nset|$ is limited by the number of vertices on the lattice. 
\begin{equation}\label{eq:sets}  
  \abs{\nset} \leq \abs{\vset} 
\end{equation}
% \input{tikzfigs/nodesetpmw}

\subsection{Node types}

There are various types of nodes that behave slightly differently. In this section, we introduce the \emph{syndrome-node} and the \emph{linking-node}, required for decoding on a toric code. For bounded surfaces such as the planar code, the \emph{boundary-node} additionally required, which is covered in Section \ref{sec:ufbbbound}. 

\begin{definition}\label{def:syndromenode}
  Let a syndrome-node $nsyndromenode$ denote a node that is seeded in a syndrome-vertex. 
\end{definition}

The node type that we have described in the previous section is a syndrome-node. Boundary vertices $v_i$ of a syndrome-node have a single seed syndrome-vertex for which there exists a minimum distance $d_i$, as stated in the proof of Theorem \ref{the:nodepmw}. This is true if all syndrome vertices are located an odd distance from each other. But this is not the case at all, as the distance between syndrome vertices is only limited by the discrete nature of the lattice and the size and boundary (if it exists) of the lattice itself. For two syndrome vertices $v_1, v_2$ located an even distance from each other, each seeds a syndrome-node $s_1, s_2$, and there exists some vertex $v_{l}$ that lie in equal distance to both syndromes. If the clusters of $s_1, s_2$ grow and reach vertex $v_{l}$ in the same growth iterations, it is not clear to which syndrome-node $v_l$ belongs, or which vertex $v_1$ or $v_2$ seeds $v_l$. 

\begin{definition}\label{def:linkingnode}
  Let a linking-node $nlinkingnode$ denote a node that is seeded in a vertex that lies in equal distance to two or more seeds of other nodes. 
\end{definition}

This problem is solved by initiating a linking-node $l$ with the vertex $v_l$ as its seed. Every boundary vertex of the nodes $s_1$ and $s_2$ is limited to having a single nearest syndrome-vertex, which are $v_1$ and $v_2$, respectively. For the linking-node, every boundary vertex in $l.\delta \vset$ is limited to having a single nearest \emph{linking-vertex} $v_l$, which is its seed. We can replace every instance of $v_\sigma$ in Theorem \ref{the:nodepmw} and its proof with $v_l$ to see that the theorem also holds for linking-nodes. Thus, a linking-node also has the property that its boundary vertex set $l.\delta \vset$ has the same potential matching weight. Note that a linking-node initiated on a vertex that lies in equal distance to the seeds of \emph{any} node, thus including other linking-nodes. 

Consider our example cluster $c_e$ of 3 nodes $\{n_1, n_2, n_3\}$ again. We slightly alter this cluster by increasing the distance between the seeds $v_1, v_2$ and $v_2, v_3$ to two edges. This means that cluster $c_e$ is only established after two growth iterations of the three previous separate cluster of node-trees $\{n_1\}, \{n_2\}, \{n_3\}$, and has a total size of 13 vertices (Figure \ref{fig:linkingode}). Now consider the vertices $v_{12}$ and $v_{23}$ that lie between $v_1, v_2$ and $v_2, v_3$, respectively. These are linking-vertices as they lie in equal distance to two seeds. Thus, in the node-tree of the merged cluster $\nset_e$, linking-nodes $l_{12}$ and $l_{23}$ are initiated. 

% \input{tikzfigs/linkingnode}

\subsection{Balanced-bloom}

The node-tree data structure can be utilized to delay the growth of boundaries with a high potential matching weight, or prioritize the growth of boundaries with a low potential matching weight, as the boundaries confined in each node have the same potential matching weight per Theorem \ref{the:nodepmw}. In order to do so, the cluster growth must be separated for the nodes in its node-tree. 

\begin{definition}\label{def:bloom}
  Let the \emph{bloom} of a node $n$ refer to the growth of the boundaries $n.\delta\vset$. The growth for all boundaries of a cluster $
  \delta\vset_j$ is the equivalent to the combined bloom of all nodes in its node-tree $\nset_j$. Let the radius of a node $nnradius$ be the number of iterations it has bloomed. 
\end{definition}

In search of a minimal weight matching, the growth of a cluster can thus prioritize the bloom of nodes with the lowest potential matching weight, and delay the bloom of nodes with larger potential matching weight. As these prioritized nodes bloom and increase in radius, the cluster moves towards equal potential matching weight across all nodes, where the number of delayed nodes decreases in each iteration. Once the equilibrium is reached, no nodes are delayed.
\begin{definition}\label{def:balancedbloom}
  Balanced-bloom is the state of growth of an odd-parity cluster $c_j$ when all nodes in its node-tree $\nset_j$ have the same potential matching weight, and thus all nodes in $\nset_j$ are bloomed. This state can be reached by prioritizing the growth of nodes with the lowest potential matching weight. 
\end{definition}
\begin{lemma}\label{lem:calconce}
  Between union events, the potential matching weight of nodes in a cluster need only to be calculated once. The delayed node can be queued for some iterations based on the difference of its potential matching weight and the minimal potential matching weight in the cluster.
\end{lemma}
\begin{proof}
  While no unions between clusters occur, the same set of nodes will define the cluster. The potential matching weight of nodes in the cluster is then defined by a potential matching $\m{C}$ (Theorem \ref{the:nodepmw}). The changes to the potential matching weight of a node $n_i$ due to the growth of the cluster, or some iterations of bloom, is directly related to its radius $n_i.r$. As we can store the radius as an attribute of the node, the altered potential matching weight is then simply an $\m{O}(1)$ calculation involving its old value and $n_i.r$. 
\end{proof}

The node-tree $\nset_j$ of a cluster $c_j$ is a reduced tree of the graph formed by $\vset_j$ and $\m{E}_j$, and is thus also a connected acyclic graph. The node-tree is stored as its root node $n_r \in \nset_j$ at the cluster $c_j.n_r$. As node-trees merge and linking-nodes are initiated, children nodes added to the set by connecting them to the parent nodes by \emph{undirected} edges. This is different from the vertex set $\vset$, which utilizes the Union-Find data structure (Section \ref{sec:ufdata}), which has \emph{directed} edges that point to the root. We will see in the next section why this is the case. 

\section{Node parity and delay}\label{sec:nodedelay}
The node-tree data structure allows for a reduction in the calculation of the potential matching weight, as the value for boundary vertices within the node are equal. However, if this calculation is done naively by calculating the potential matching weight for each node individually, where the entire node-tree is traversed in each calculation, the full calculation runs in quadratic time. Luckily, as we will explore in this section, the node-tree data structure allows us to calculate several values that relate closely to the potential matching weight, the \emph{node parity} and \emph{node delay}, by two depth-first searches from the root node. 

\begin{definition}\label{def:nodedelay}
  Let the \emph{node delay} $nndelay$ be the difference in the number of bloom delay iterations of a node $n$ and the root node $n_r$ in the node-tree of an odd-parity cluster.
\end{definition}

\begin{definition}\label{def:nodeparity}
  Let the \emph{node parity} $nnparity$ be an indicator for whether a node $n_\beta$ has a larger delay than its parent in an odd-parity cluster. For even parity $n_\beta.p=0$, then $n_\beta.d < n_\alpha.d$. For odd parity $n_\beta.p=1$, then $n_\beta.d > n_\alpha.d$. Even nodes are relatively prioritized, and odd nodes are relatively delayed.
\end{definition}

\begin{theorem}\label{the:delayequation}
  The node parity of a node $n_\beta$ is only dependent on its own attributes and its children $\{n_{\gamma,1}, ...\}$:
  \begin{equation}\label{eq:nodeparity}
    n_\beta.p =
    \begin{cases}
      \big( \sum_{n_\gamma} (1-n_\gamma.p) \big ) \bmod 2 \hspace{1em} | \hspace{1em} n_\gamma \text{ child node of } n_\beta & n_\beta \equiv s_\beta \\
      1 - \big( \sum_{n_\gamma} (1-n_\gamma.p) \big ) \bmod 2 \hspace{1em} | \hspace{1em} n_\gamma \text{ child node of } n_\beta & n_\beta \equiv l_\beta.
    \end{cases} 
  \end{equation}
  The node delay of a node $n_\beta$ is only dependent on its own attributes and its parent $n_\alpha$:
  \begin{multline}\label{eq:delayequation}
    s_\beta.d = s_\alpha.d + \Bigg \lceil k_{eq} \Bigg( 2\bigg(\ceil{\frac{s_\beta.r}{2}} - \floor{\frac{s_\alpha.r + s_\beta.r \bmod 2}{2}} - (-1)^{s_\beta.p}\abs{(s_\beta,s_\alpha)}\bigg)
    \Bigg) - \\
    (s_\beta.r - s_\alpha.r) \bmod 2 \Bigg \rceil \hspace{1em} | \hspace{1em} s_\beta \neq s_r,
  \end{multline}
  where $n.r$ denotes the node radius (Definition \ref{def:bloom}) and $k_{eq}$ is an optimization parameter.
\end{theorem}
\begin{proof}
  Lemmas \ref{lem:nodeparitypart} and \ref{lem:nodeparity} prove Equation \ref{eq:nodeparity}. The analyses leading up to Equations \eqref{eq:1ddelay} and \eqref{eq:2ddelay}, and Lemma \ref{lem:keq} prove Equation \eqref{eq:delayequation}.
\end{proof}

We will prove Theorem \ref{the:delayequation} throughout the following sections. In Section \ref{sec:1dnodetree}, we introduce the concept of node delays and parities on syndrome-nodes through an example of a one-dimensional node-tree. In Section \ref{sec:realisticnodetree}, the same concept is applied to realistic node-trees. These concepts are extended to linking-nodes in Section \ref{sec:linkparitydelay}. In Section \ref{sec:eqstate}, we introduce the concept of the \emph{equilibrium-state} of a node-tree that optimizes the minimal weight behavior through the $k_{eq}$ parameter. Finally, the pseudo-codes for the calculation of node delays are listed in Section \ref{sec:pdccalc}.

\subsection{One-dimensional node-tree parity and delay}\label{sec:1dnodetree}
% \input{tikzfigs/onedimensialtree}

We introduce the concepts of node parity and node delay from Definitions \ref{def:nodeparity} and \ref{def:nodedelay} through a one-dimensional node-tree $\nset_{1D}$ of exclusively syndrome-nodes. In this simplification, all nodes lie on a horizontal line from $s_1$ to $s_{|\nset_{1D}|}$ (Figure \ref{fig:1dnodetree}). Let us calculate the potential matching weights for the nodes in this cluster. Recall from Definition \ref{def:bloom} that the radius of the node $s.r$ is equal to the number of bloom iterations, one half-edge on the boundaries per iteration. This means that if a merge with some other cluster occurs on a boundary edge of $s$, the weight of the matching edges within the node $s$ is equal to $\floor{s.r/2}+1$ or. For a merge on $s_1$, the matching weight $|\m{C}|$ is the sum of $\floor{s.r/2}+1$, the length of edges $(s_2,s_3), (s_4,s_5)$, and some value $k$ corresponding to the weight of matching edges in the remainder of the cluster. This calculation can be continued for other nodes:
\begin{align*}
% \nonumber % Remove numbering (before each equation)
  PMW(s_1) &= \floor{s_1.r/2}+1 + \abs{(s_2,s_3)} + \abs{(s_4,s_5)} + k \\
  PMW(s_2) &= \floor{s_2.r/2}+1 + \abs{(s_1,s_2)} + \abs{(s_2,s_3)} + \abs{(s_4,s_5)} + k \\
  PMW(s_3) &= \floor{s_3.r/2}+1 + \abs{(s_1,s_2)} + \abs{(s_4,s_5)} + k\\
  &\vdots
\end{align*}
The difference in the potential matching weight of a node $s_i$ and its parent $s_{i-1}$ has a more constant definition that is only dependent on the radii of $s_i$,  $s_{i-1}$, and the length of the edge connecting the two:
\begin{align*}
% \nonumber % Remove numbering (before each equation)
  PMW(s_2) - PMW(s_1) &= \floor{s_2.r/2} - \floor{s_1.r/2} + \abs{(s_1,s_2)} \\
  PMW(s_3) - PMW(s_2) &= \floor{s_3.r/2} - \floor{s_2.r/2} - \abs{(s_2,s_3)} \\
  &\vdots
\end{align*}

There is a trend in which the contribution of the edge length to the difference in the potential matching weight is dependent on the \emph{parity} of the node number $i$. The difference $ PMW(s_{2i}) - PMW(s_{2i-1})$ for some integer $i$ has the positive addition of $|(s_{2i}, s_{2i-1})|$, whereas the difference $ PMW(s_{2i+1}) - PMW(s_{2i})$ has the subtraction of $|(s_{2i}, s_{2i-1})|$. Thus, we can generalize the difference as
\begin{equation}\label{eq:pmwdiff}
  PMW(s_i) - PMW(s_{i-1}) = \floor{\frac{s_i.r}{2}} - \floor{\frac{s_{i-1}.r}{2}} + (-1)^{i}\abs{(s_i,s_{i-1})} \hspace{1em} | \hspace{1em} i\geq 2.
\end{equation}

\begin{lemma}
  The difference in delay between a node $s_i$ and its parent $s_{i-1}$ is related to the difference in potential matching weight by 
  \begin{equation}\label{eq:delaydiff}
    s_i.d - s_{i-1}.d =2\big(PMW(s_i) - PMW(s_{i-1})\big) + f_{deg}(s_i.r, s_{i-1}.r) \hspace{1em} | \hspace{1em} i\geq 2,
  \end{equation}
  where $f_{deg}$ is a repair function that accounts for the degeneracy of the potential matching weight with
  \begin{equation}\label{eq:degenrepair}
    f_{deg}(R_i, R_{i-1}) = (R_i - R_{i-1}) \bmod 2 \cdot \left(\frac{R_i - R_{i-1}}{\abs{R_i - R_{i-1}}}\right) \cdot (-1)^{\left(\frac{R_i+R_{i-1}-1}{2}\right)\bmod 2} .
  \end{equation}
\end{lemma}
\begin{proof}
  As the boundary edges grow only a half-edge per bloom, the difference in the node delays between a node $s_i$ and its parent $s_{i-1}$ is thus twice the difference in their potential matching weights. But also due to this discrete multiplication factor of 2 between the delay and the potential matching weight, there is a degeneracy when calculating the potential matching weights from the node radii. For example, the radii $s_i.r = s_{i-1}.r = 2k$ for some integer $k$ yields the same potential matching weight as $s_i.r = 2k$, $s_{i-1}.r = 2k + 1$.

  The degeneracy between the node radius $R_i$ and the parent node radius $R_{i-1}$ exists only if the difference between the radii is odd. This is due to the division by 2 and the subsequent floor function. Thus, the degeneracy repair function $f_{deg}$ acts only when $(R_i - R_{i-1}) \bmod 2$ is 1. 
  
  Disregarding the length of edges between two subsequent nodes, for nodes $s_i, s_{i-1}$ with radii $R_i-R_{i-1}=1$, node $s_i$ is thus larger and should have delay $+1$ compared with node $s_{i-1}$. For radii $R_i-R_{i-1}=-1$, node $s_i$ should have delay $-1$ compared with node $s_{i-1}$. This can be simplified with
  \begin{equation}\label{eq:nodediff}
    s_i.d - s_{i-1}.d = \frac{R_i - R_{i-1}}{\abs{R_i - R_{i-1}}} \hspace{1em} | \hspace{1em} \abs{R_i - R_{i-1}} = 1.
  \end{equation}
  
  Furthermore, we find that the degeneracy is caused by a non-linearity in the difference of the potential matching weights:
  \begin{equation}\label{eq:nonlinear}
    \floor{R_i/2}-\floor{R_{i-1}/2} = 
    \begin{cases}
      \pm 2\abs{R_i - R_{i-1}} & \text{if } \left(\frac{R_i+R_{i-1}-1}{2}\right)\bmod 2 = 1 \\
      \pm 2(\abs{R_i - R_{i-1}} - 1) & \text{else}.
    \end{cases}
  \end{equation}
   The non-linearity can be accounted for by combining Equation \eqref{eq:nodediff} with the condition of Equation \eqref{eq:nonlinear} to obtain the repair function of Equation \eqref{eq:degenrepair}, which proves the lemma. 
\end{proof}

Combining Equations \eqref{eq:pmwdiff} and \eqref{eq:delaydiff}, we find that the delay of a node is defined as
\begin{multline}\label{eq:1ddelaycomp}
  s_i.d = s_{i-1}.d + 2\bigg(\floor{\frac{s_i.r}{2}} - \floor{\frac{s_{i-1}.r}{2}} + (-1)^{i}\abs{(s_i,s_{i-1})}\bigg) + \\
  (s_i.r - s_{i-1}.r) \bmod 2 \cdot \left(\frac{s_i.r - s_{i-1}.r}{\abs{s_i.r - s_{i-1}.r}}\right) \cdot (-1)^{\left(\frac{s_i.r+s_{i-1}.r-1}{2}\right)\bmod 2} \hspace{1em} | \hspace{1em} i\geq 2,
\end{multline}
which can be further simplified to 
\begin{multline}\label{eq:1ddelay}
  s_i.d = s_{i-1}.d + 2\Bigg(\ceil{\frac{s_i.r}{2}} - \floor{\frac{s_{i-1}.r + s_i.r \bmod 2}{2}} + (-1)^{i}\abs{(s_i,s_{i-1})}\Bigg) - \\
  (s_i.r - s_{i-1}.r) \bmod 2 \hspace{1em} | \hspace{1em} i\geq 2,
\end{multline}
where the repair function $f_{deg}$ has been partially moved into the main part of the function. We will not provide a description of this simplification, but Equation \eqref{eq:1ddelay} has the exact same output as Equation \eqref{eq:1ddelaycomp}. 

Using equation \eqref{eq:1ddelay}, we can calculate all the node delays in the one-dimensional node-tree by setting some initial delay for $s_1$, for example, $s_1.d=0$. This is why the node delay is defined as the difference in the bloom delay iterations between a node and the root node, which is $n_r=s_1$ in the one-dimensional node-tree. The node delay can thus also take negative values, as the choice for $s_1.d$ is arbitrary. The absolute delay, the number of iterations for a node to wait, can then be calculated by subtracting the minimum delay in the node-tree $\min \{s.d | s \in \nset_{1D}\}$. Not to mention, as the potential matching weight does not change between union events (Lemma \ref{lem:calconce}), the node delays do not have to be recalculated in every iteration. This means that it is necessary to add to the number of iterations a node has waited.
\begin{definition}\label{def:absolutedelay}
  Let $nnwait$ denote the number of bloom iterations a node $n$ has already \emph{waited}, then the \emph{absolute delay} $gls{nndelaya}$ of a node $n$ in a cluster $c_j$ with node-tree $\nset_j$ is the actual number of blooms to wait at any given moment. The absolute delay is calculated with
  \begin{equation}\label{eq:absulutedelay}
    n_i.D = n_i.d - c_j.d - n.w, 
  \end{equation}
  where $c_j.d$ is the minimum delay value in the cluster
  \begin{equation}\label{eq:cd}
    c_j.d = \min \{n.d \hspace{.5em} | \hspace{.5em} n\in \nset_j\}.
  \end{equation}
\end{definition}

Note that in Definition \ref{def:absolutedelay}, the general node element $n$ is used instead of the syndrome-node $s$. This definition also holds for other types of nodes, such as linking-nodes (Section \ref{sec:linkparitydelay}) or boundary-nodes (Section \ref{sec:ufbbbound}). The balanced-bloom state (Definition \ref{def:balancedbloom}) is thus reached when $n_i.D = 0$ for all nodes in the node-tree. 

\subsection{Realistic node-tree parity and delay}\label{sec:realisticnodetree}

The one-dimensional node-tree from the previous section does not accurately represent node-trees that occupy a real lattice. On a two-dimensional lattice (independent noise) and a three-dimensional lattice (phenomenological noise), the node-tree $\nset$ is allowed to form in the same dimensions as an acyclic graph, instead of a linear set with index number $i$. The delay calculation on an entire node tree is not a sequence of calculations from node $s_1$ to $s_{|\nset_{1D}|}$, but a depth-first search from the root node $s_r$. Just as the previous section, we assume that $\nset$ has excursively syndrome-nodes. Using the same strategy as in the previous section, we find that the equation for calculating the node delays is quite similar. The delay calculation is performed on a node $s_\beta$ comparatively with the parent node $s_\alpha$, which means that there must be some directed path within $\nset$, such that there is a clear direction, and the calculation is started from the root node $s.r$ by setting $s.r.d=0$.

The edge contribution to the node parity $|(s_\beta, s_\alpha)|$, whose sign was previously determined by the node index $i$, is now set by the node parity (Definition \ref{def:nodeparity}). 
\begin{lemma}\label{lem:nodeparitypart}
  For a node-tree of exclusively syndrome-nodes, the node parity concept can be defined as the number of descendant nodes modulo 2 (see Figure \ref{fig:parities}). It can be calculated without counting the number of descendants for every node by using the recursive relation where the parity of a node $n_\beta$ is only dependent on the parities of its immediate children $n_\gamma$:
  \begin{equation}\label{eq:nodeparitypart}
    s_\beta.p = \big( \sum_{s_\gamma} (1-s_\gamma.p) \big ) \bmod 2 \hspace{1em} | \hspace{1em} s_\gamma \text{ child node of } s_\beta.
  \end{equation}
\end{lemma}
\begin{proof}
  For a node $s_\beta$ with a set of children nodes $\{s_\gamma, ...\}$, the node parity $s_\beta.p$ can only be even if it has an even number of children nodes with even parity $s_\gamma.p = 0$, and an even number of children nodes with odd parity $s_\gamma.p=1$. This is accomplished by Equation \ref{eq:nodeparitypart}. 
\end{proof}
Note that this definition of the node parity is identical as in a one-dimensional syndrome-node-tree, where a node with an odd index effectively has an even number of descendant nodes and results in a contribution $-|(s_i, s_{i-1})|$ and an even indexed node results in a contribution $+|(s_i, s_{i-1})|$. The parity calculation thus requires the parity of every child node to be known. This means that the parity calculation of $\nset$ is related to a depth-first search from the root node $s_r$, with a tail-recursive function to calculate the parities from the bottom up. To calculate the node delays within $\nset$, a second depth-first search is applied with

\begin{multline}\label{eq:2ddelay}
  s_\beta.d = s_\alpha.d + 2\Bigg(\ceil{\frac{s_\beta.r}{2}} - \floor{\frac{s_\alpha.r + s_\beta.r \bmod 2}{2}} - (-1)^{s_\beta.p}\abs{(s_\beta,s_\alpha)}\Bigg) - \\
  (s_\beta.r - s_\alpha.r) \bmod 2 \hspace{1em} | \hspace{1em} s_\beta \neq s_r,
\end{multline}
where $n_\beta$ is the node of interest, and $n_\alpha$ is a parent of $n_\beta$, and the sign of the edge component is now dependent on the node parity $s.p$.

% \input{tikzfigs/parities}

\subsection{Linking-node parity and delay}\label{sec:linkparitydelay}

Up until now, the existence of linking-nodes has been neglected in the node parity and delays calculations. In this section, we will extend upon the previous equations for node parity and delay to include linking-nodes. Luckily, the delay calculation of Equation \eqref{eq:2ddelay} still holds for linking-nodes. However, the parity of a linking-node is calculated differently. Consider an example node-tree $\nset_s$ with five syndrome-nodes $\{s_1,...,s_5\}$ lined up linearly with distance 1 between them and $n_r = s_1$ (Figure \ref{fig:linkingparity}a). Let us consider a delay $n.d^*$ from Equation \eqref{eq:2ddelay} but leaving out the node radius components as we are now only interested in the parity component $- (-1)^{s_\beta.p}\abs{(s_\beta,s_\alpha)}$. The parity of $s_4$ is odd, therefore
\begin{equation*}
  s_4.d^* = s_3.d^* + 2(s_3, s_4).
\end{equation*}

% \input{tikzfigs/linkingparity}

Consider now a second example node-tree $\nset_l$ with three syndrome-nodes and two linking-nodes $\{s_1, l_2, s_3, l_4, s_5\}$ (Figure \ref{fig:linkingparity}b). Recall that a linking-node does not have a syndrome-vertex as seed, and thus matching must occur between seeds of the syndrome-nodes. The potential matching weights without the radius component $PMW^*$ in $\nset_l$ are
\begin{align*}
  PMW^*(s_1) &= \abs{(s_1, l_2)} + \abs{(l_1, s_3)} + \abs{(l_3, l_4)} + \abs{(l_4, s_5)} \\
  PMW^*(l_2) &= \abs{(s_1, l_2)} + \abs{(l_3, l_4)} + \abs{(l_4, s_5)} \\
  PMW^*(s_3) &= \abs{(s_1, l_2)} + \abs{(l_1, s_3)} + \abs{(l_3, l_4)} + \abs{(l_4, s_5)} \\
  PMW^*(l_4) &= \abs{(s_1, l_2)} + \abs{(l_1, s_3)} + \abs{(l_4, s_5)} \\
  PMW^*(s_5) &= \abs{(s_1, l_2)} + \abs{(l_1, s_3)} + \abs{(l_3, l_4)} + \abs{(l_4, s_5)},
\end{align*}
and the delays in $\nset_l$ are 
\begin{align*}
  l_2.d^* &= s_1.d^* + 2(l_2, s_1)\\
  s_3.d^* &= l_2.d^* + 2(s_3, l_2)\\
  l_4.d^* &= s_3.d^* - 2(l_4, s_3)\\
  s_5.d^* &= l_4.d^* - 2(s_5, l_4).
\end{align*}

\begin{lemma}\label{lem:nodeparity}
  The parity equation \eqref{eq:nodeparitypart} can be altered to apply for both syndrome-nodes and linking-nodes by   
  \begin{equation}
    n_\beta.p =
    \begin{cases}
      \big( \sum_{n_\gamma} (1-n_\gamma.p) \big ) \bmod 2 \hspace{1em} | \hspace{1em} n_\gamma \text{ child node of } n_\beta & n_\beta \equiv s_\beta \\
      1 - \big( \sum_{n_\gamma} (1-n_\gamma.p) \big ) \bmod 2 \hspace{1em} | \hspace{1em} n_\gamma \text{ child node of } n_\beta & n_\beta \equiv l_\beta.
    \end{cases}\tag{\ref{eq:nodeparity}}
  \end{equation}
\end{lemma}
\begin{proof}
  The node parities of subsequent syndrome-nodes in a node tree should be independent on the number of intermediate linking-nodes, as the matching only occurs between the syndrome-vertex seeds of the syndrome-nodes. The parities of the intermediate linking-nodes should thus satisfy this requirement. By applying 1 minus the definition for the parity of a syndrome-node, the parity of the nearest descendant syndrome-node is effectively passed on to the linking-node, so that the parity flip only occurs at the next syndrome-node when moving upwards in the node-tree. 
\end{proof}

\subsection{Node tree ancestry}
Recall from the last paragraph of Section \ref{sec:nodeset} that the edges of the node tree are \emph{undirected}. However, the depth-first searches to calculate the node parities and delays indicate that there is some ancestry in the node tree. In this section, we will clarify this feature of the node-tree. 
\begin{lemma}\label{lem:anynoderoot}
  Any node $n_i \in \m{N}$ is a valid root. The root $n_r$, which has parity $n_r.p=0$, determines the node parities within the node-tree. 
\end{lemma}
\begin{proof}
  Since the node parities are calculated from the descendants to the root and the node delays are subjected to an arbitrarily chosen delay for the root $n_r.d$, any node in $\nset$ can be chosen as the root. Recall from Definition \ref{def:nodeparity} that the node parity is only defined for an odd-parity cluster. For a node-tree of exclusively syndrome-nodes, $n_r$ must have an even number of descendant nodes, and thus per Lemma \ref{lem:nodeparitypart}, it must be that $s_r.p=0$. From a node-tree of mixed syndrome-nodes and linking-nodes, recall from Lemma \ref{lem:nodeparity} that linking-nodes always copies the parity of the nearest descendant syndrome-node, thus $n_r.p=0$. Choosing which node $n_i \in \nset$ is the root node $n_r$, for this reason, determines the parities in the node-tree (see Figure \ref{fig:parities}). 
\end{proof}

The node-tree has undirected edges, such that it is not set in stone which node is the root. When to clusters merge into one, their respective node trees need to be merged too. As the edges in the node-tree reflect one or many physical edges on the lattice, the merge of node-trees can not be applied by simply pointing one root to another, such as in the Union-Find data structure. Instead, the node-trees $\nset_i, \nset_j$ are joined on the nodes $n_i \in \nset_i, n_j\in \nset_j$ containing the boundary vertices that support the newly grown edge that links the clusters. This can be done by setting one of the nodes $n_i$ or $n_j$ as the \emph{subroot} if its tree, and connecting it with the other. This motivates the use of undirected edges. New roots can be chosen that allow for the union of node-trees. More on the union of node-trees is described in Section \ref{sec:nodejoin}. 

\begin{lemma}\label{lem:nodecalc_ancestrypath}
  The calculated node delays $n_i.d$ are only valid, while node parities have been calculated with the same root node $n_r$. The absolute delay $n_i.D$ is independent of the selected root node. 
\end{lemma}
\begin{proof}
  Since both the calculation of the node parities and node delays are performed by a depth-first search of the node tree, and the node parities are dependent on which node is set as root (Lemma \ref{lem:anynoderoot}), it is trivial that the node delay calculation should follow the same depth-first search as the parity calculation. The absolute delay $n_i.D$ is independent of the root node, as it is the node delay $n_i.d$ minus the minimal delay in the cluster $c.d$ (Definition \ref{def:absolutedelay}). Recall that the node delay value is the difference in delay with the root node $n_r.d$, whose value is arbitrary. By subtracting the minimal delay value in the cluster, this arbitrariness is accounted for. 
\end{proof}


%  An interesting aspect of the node delays is that the differential delays $\delta(n.d)$ are indifferent for which node is set as root $n_r = n$. The root delay value $n.d$ however may differ for different roots as de delay value for the root node is arbitrary. But as we subtract by the minimal delay $C.d$ to find the normalized delay, the root dependance of node PMW and node PNW is accounted for. This fact strengthens Lemma \ref{lem:anynoderoot}.

\subsection{Equilibrium optimization}\label{sec:eqstate}

In this section, we alter the delay equation \eqref{eq:2ddelay} with a new parameter $k_{eq}$ to optimize a trade-off in this algorithm. This trade-off occurs in about $50\%$ of the node-tree unions in the event that we dub \emph{parity-inversion}. Recall from Lemma \ref{lem:calconce} that after a union, the potential matching weight within the node-tree changes, and the parities and delays may have to be recalculated. We will describe in Section \ref{sec:growingcluster} necessary steps to grow a cluster with the node-tree data structure, and in Section \ref{sec:nodejoin}, we describe how to merge node-trees. In this section, the focus is on what happens to the potential matching weight and the subsequently required recalculation of the node parities and delays. 

When clusters grow in size, their nodes are delayed such that the equilibrium in the potential matching weight can be reached. Because of this, the prioritized nodes have larger radii than the delayed nodes. As clusters merge, their node-trees are also joined on the nodes that contain the vertices supporting the connecting edge. Due to the merges, the parities of nodes in parts of the joined node-tree may flip. 
\begin{definition}\label{def:parityinversion}
  Parity inversion is the event of that the parities within a part of a node-tree flip, which may happen as a result of the merging of multiple node-trees. 
\end{definition}
This means that the previously prioritized nodes become the nodes to be delayed, and the previously delayed nodes are to be prioritized. As these nodes have already grown in different radii, the parity inversion causes that after the flip in priority, it takes twice as many iterations to reach the equilibrium in potential matching weight. As more and more unions occur, the number of parity inversions increases, and so does the number of iterations needed to reach equilibrium. 

\begin{definition}\label{def:eqstate}
  The equilibrium-state $(I:M)$ of cluster describes the degree of potential matching weight equilibrium in the cluster with node-tree $\nset$, where $M$ is the number of iterations with delayed blooms needed to reach equal potential matching weight, and $I\leq M$ is the number of iterations grown while equal potential matching weight has not been reached (Figure \ref{fig:eqstate}). The $(M:M)$ equilibrium-state is maximally occupied when all nodes in the node-tree have equal potential matching weights, which is equivalent to the balanced-bloom state of Definition \ref{def:balancedbloom}. 
\end{definition}
% \begin{figure}
%   \centering
%     \begin{tikzpicture}
%       \DSPECTRUM{4}{2}{1}
%       \draw (-1.5,.5) node[align=right] {Unbalanced} ++(6.6,0) node[align=left] {Balanced};
%     \end{tikzpicture}
%   \caption{Visual representation of the equilibrium-state $(2:4)$. The size of the full x-axis is $M=4$ and the length of the bar is $I=2$. The left side of the spectrum is equivalent to the unbalanced equilibrium-state, and the right the balanced state.}\label{fig:eqstate}
% \end{figure}
For example, a cluster with $M=4$ requires 4 growth iterations to reach an equilibrium in potential matching weight in all nodes in the cluster. The equilibrium-state thus gives us an indication of how near balanced-bloom a cluster performs. 
\begin{lemma}\label{lem:eqstate}
  Let $(I_t, M_t)$ denote the equilibrium-state of a cluster just before a union with another cluster that causes a parity inversion, and $(I_{t+1}, M_{t+1})$ the equilibrium-state after the union, then $I_t \propto M_{t+1}$.
\end{lemma}
\begin{proof}
  In the context of the equilibrium-state, the delayed bloom of nodes in cluster growth is equivalent to increasing the value of $I$ in the equilibrium-state. As $I_t\to M_t$, the difference between the radii of the prioritized and delayed nodes increases. Thus, the iterations $M_a$ needed after the union and parity inversion also increases. 
\end{proof}
Subsequent parity inversions cause a gradual but certain increase in $M$ of the equilibrium-state, depending on $(I_t:M_t)$ during the parity inversion at the union, requiring a growing number of growth iterations $I_{t+1}$ to reach the equilibrium-state $(M:M)_{t+1}$. As the lattice size is increased, the total number of unions of a cluster with other clusters also increases, leading to a growing number of parity inversions. Thus increasing the lattice size has the consequence that more growth iterations $I$ are needed to reach equilibrium-state $(M:M)$. This is the trade-off in the effectiveness of this algorithm. On the one hand, it is preferred that $I\to M$ to maximally occupy the equilibrium-state that is a heuristic for minimum-weight, but on the other, $I$ is also proportional to the number of iterations needed to actually reach $(M:M)$ due to parity inversions. 

\begin{definition}\label{def:keq}
  Let the \emph{equilibrium factor} $zkeq\in [0,1]$ be a target factor $I/M$ to the node delay. 
\end{definition}
\begin{lemma}\label{lem:keq}
  The delay equation where the delays have a factor $k_{eq}\in [0,1]$ minimizes the trade-off caused by parity inversion. 
  \begin{multline}
    s_\beta.d = s_\alpha.d + \Bigg \lceil k_{eq} \Bigg( 2\bigg(\ceil{\frac{s_\beta.r}{2}} - \floor{\frac{s_\alpha.r + s_\beta.r \bmod 2}{2}} - (-1)^{s_\beta.p}\abs{(s_\beta,s_\alpha)}\bigg)
    \Bigg) - \\
    (s_\beta.r - s_\alpha.r) \bmod 2 \Bigg \rceil \hspace{1em} | \hspace{1em} s_\beta \neq s_r. \tag{\ref{eq:delayequation}}
  \end{multline}
\end{lemma}
\begin{proof}
  For any $k_{eq} < 1$, a cluster will never actually reach the $(M:M)$ equilibrium-state, only $(k_{eq}M:M)$. Consequently, after a parity inversion, the difference in node radii between prioritized and delayed nodes is decreased, such $I\to k_{eq}M$ can be reached in a lower amount of growth iterations. 
\end{proof}

In Figure \ref{fig:kbloom} and \ref{fig:kbloom2}, a comparison is made between the growth of a set of node-trees using Equation \eqref{eq:delayequation} with $k_{eq}=1$ (same as Equation \eqref{eq:2ddelay}) and with $k_{eq}=1/2$. Here, the equilibrium-state is defined as $(I:k_{eq}M)$. We see that the number of iterations needed to maximally occupy the equilibrium state using $k_{eq}$ is halved before and after the union with parity inversion when using $k_{eq} = 1/2$. 

The optimal value of $k_{eq}$ may be dependent on the number of parity inversions, the lattice size, growth iteration, and the node-tree and cluster sizes $|\nset|, |\vset|$, with the goal of maximally occupying the equilibrium-state after the last parity inversion. We suspect that because $M$ doubles after parity inversion, a constant factor of $k_{eq}=1/2$ should behave well on average, as the equilibrium state is occupied half on average. However, other values of $k_{eq}$ should be explored, and optimizations dependent on these variables could be possible. 

% \input{tikzfigs/equilibrium_state}
 
\subsection{Parity and delay calculations}\label{sec:pdccalc}

With equation \eqref{eq:nodeparity} and \eqref{eq:delayequation}, we now finally have the tools to formulate the algorithms to calculate the node parities and delays. For a node-tree with root $n_r$, we can calculate the parities by calling the \emph{head recursive} function \codefunc{Calcparity} on $n_r$ in Algorithm \ref{algo:calcparity}, where we perform a reverse depth-first search of the node-tree. The node delays are calculated by calling the \emph{tail recursive} function \codefunc{Calcdelay} in Algorithm \ref{algo:calcdelay}, where we perform a second depth-first search of the node-tree. This parity and delay calculation will from this point sometimes be abbreviated as PDC. A schematic of the directions of these calculations in an example node-tree is included in Figure \ref{fig:2dfs}.

% \input{pseudocodes/calcparity}
% \input{pseudocodes/calcdelay}
% \input{tikzfigs/paritydelay}

\section{Growing a cluster}\label{sec:growingcluster}
With the knowledge of the previous section, we now have the equations and algorithms available to describe the steps to grow a cluster in the context of Union-Find Balanced-Bloom. Previously, in the Union-Find decoder, a cluster is grown with $\codefunc{Grow}(c_j, \m{L}_m)$ (Algorithm \ref{algo:ufgrow}). Here, the boundary edges connected to the vertices in $c_j.\delta\vset$ are grown by increasing the value of $e.support$. If $e.support = 2$, $e$ is added to the merging list $\m{L}_m$ to merge the vertex-trees at some later moment. 

In the node-tree data structure, the growth of a cluster is equivalent to a depth-first search of the node-tree, which will now be performed by $\codefunc{Ngrow}$ (Algorithm \ref{algo:bbgrow}). The boundary list for each cluster is not stored at the cluster $c_j$, but separately stored at each of the nodes $n_i$ in $\m{N}_j$ by $n_i.\delta\vset$. We travel to all $n_i \in \m{N}_j$ from the root $n_r$ and apply $\codefunc{Bloom}(n_i)$ (Algorithm \ref{algo:bloom}), which grows the boundaries for each node individually. Again, if an edge on the boundary are grown to $e.support = 2$, $e$ is added to the merging list $\m{L}_m$. Elements of $\m{L}_m$ are then iterated over to merge the vertex-trees and node-trees at some later moment. The merging of node-trees is considered in Section \ref{sec:nodejoin}. 

Recall from Theorem \ref{def:balancedbloom} that with Balanced-Bloom, the bloom of node with the lowest potential matching weight in the cluster are prioritized, whereas the bloom of other nodes are delayed. Also, from Lemma \ref{lem:calconce}, in the absence of unions, the delays are not recalculated after every growth iteration, but stored in memory at the nodes. Definition \ref{def:absolutedelay} introduced the absolute delay $n_i.D$, where the actual number of iterations to delay is updated via the minimal delay value $c_j.d$ in the cluster, and the number of iterations already waited for $n.w$. Thus, when performing the depth-first search in \codefunc{Ngrow}, a node should be conditionally bloomed if only $n_i.D = 0$ is satisfied. If not, node $n_i$ is skipped, the wait $n.w$ is increased, and the depth-first search continues recursively on its children nodes. 

% \input{pseudocodes/bloom}
% \input{pseudocodes/ngrow}

\section{Joining node-trees}\label{sec:nodejoin}
Within the vertex-tree $\m{V}$, which utilizes the Union-Find data structure, \emph{path compression} and \emph{union by weight} or \emph{union by rank} are applied to minimize the depth of the tree. These rules minimize the calls to the \codefunc{Find} function. Similarly, in the node-tree $\m{N}$, we would also like to apply a set of rules to reduce the calls to \codefunc{Calcparity} and \codefunc{Calcdelay}, which we will dub the parity and delay calculation minimization.

\begin{definition}\label{def:partialpdc}
  A partial parity or partial delay calculation, which will often be abbreviated to a partial calculation, is associated with a depth-first search that is not initiated from the root node $n_r$, but some descendant node of $n_r$ in the node-tree. 
\end{definition}

This minimization is achieved by preserving the node parities and delays in subsets of the merged node-tree after union, and applying a partial calculation of the parities and delays in the remaining subsets if required. The recursiveness of both \codefunc{Calcparity} and \codefunc{Calcdelay} (Algorithms \ref{algo:calcparity} and \ref{algo:calcdelay}) ensures that this is possible. The tail-recursive parity calculation stops at the node where the depth-first search is started, and the head-recursive delay calculation now has a non-arbitrarily node delay. 

With the addition of the node-tree data structure, during the merge of clusters $c_\alpha$ and $c_\beta$, we have to additionally merge the node-trees $\m{N}_{\alpha}$ and $\m{N}_\beta$ that require its own set of rules that we will explain in this section. Let us first make a clear distinction between the various methods. For the merge of vertex-trees $\vset_\alpha, \vset_\beta$ we apply $\codefunc{Union}(v_\alpha, v_\beta)$ (Algorithms \ref{algo:unionweight} or \ref{algo:unionrank}), with the two vertices spanning the edge connecting two clusters as arguments. For the merge of node-trees $\nset_\alpha, \nset_\beta$, we introduce here $\codefunc{Join}(n^\alpha, n^\beta)$ (Algorithm \ref{algo:join}), which is called on the two nodes $n_\alpha, n_\beta$ that seed vertices $v^\alpha, v^\beta$, respectively. During a merge of two clusters, these routines are both applied to their respective sets. Within the context of the Union-Find Balanced-Bloom decoder, when either one of the expressions ``merge clusters $C_\alpha$ and $C_\beta$'', ``the union of vertex-trees $\m{V}_\alpha$ and $\m{V}_\beta$'' or the ``join of node-trees $\m{N}_{\alpha}$ and $\m{N}_\beta$'' is mentioned, it is always implied that both routines are executed.

\begin{definition}\label{def:nodesetparity}
  Let the parity of a node-tree be the number of syndrome-nodes in the node-tree modulo 2. The parity of the node-tree is thus equivalent to the parity of its cluster. 
\end{definition}
Let us categorize the joins of two node-trees into two types: even-joins and odd-joins, depending on the parity of the node-tree after the join. 
\begin{definition}\label{def:oddevenjoin}
  An even-join may be the result of the join of two even node-trees or two odd node-trees, whereas an odd-join is the result of the join of one odd node-tree and one even node-tree.
\end{definition}

\begin{lemma}\label{lem:nodecalc_even}
  If node-trees merge into an even node-tree $\nset^e$, all node parities and delays within $\nset^e$ become invalid or \emph{undefined}. 
\end{lemma}
\begin{proof}
  Recall from Definitions \ref{def:nodeparity} and \ref{def:nodedelay} that the node parity and delay are only defined for odd-parity clusters. An even-parity cluster does not have a potential matching weight, as the matching within the cluster is already defined. However, $\nset^e$ can merge with another odd-parity cluster with node-tree $\nset^o$ in a larger odd-join. In that case, we might think about ``reusing'' some node parities and delays that were already calculated in $\nset^e$. To reuse prior calculated parities and delays, a depth-first search on $\nset^e$ is needed to find which sections are still valid, and which sections are not. This is especially the case when the clusters in the even-join are the results of joins within the same growth iteration. Checking the validity to reuse prior parities and delays then acquires the same complexity as redoing the calculation of parity and delays over the subtree $\nset^e$. Hence, the node parities and delays in the joined set after an even-join are \emph{undefined}.
\end{proof}

\begin{lemma}\label{lem:nodecalc_odd}
  Consider an odd-join on nodes $n_j^e \in \nset^e, n_j^o\in \nset^o$, belonging to an even and an odd node-tree, respectively. Parity and delay calculations are minimized if the node-trees are always joined by setting $n_j^e$ as the child of $n_j^o$. 
\end{lemma}
\begin{proof}
  If $n_j^e$ is made a child of $n_j^o$, $n_j^e$ is the new subroot of subtree $\nset^e$, and an even number of syndrome-nodes are now descendants of $n_j^o$, and parities within $\nset^o$ and its root are unchanged. Recall from Lemma \ref{lem:nodecalc_ancestrypath} that thus the delays in $\nset^o$ are also unchanged. A partial parity and delay calculation can now be initiated from $n_j^e$ and is proportional to $|\nset^e|$ (Figure \ref{fig:joinrules}b). If $n_j^o$ is made a child of $n_j^e$, an odd number of syndrome-nodes are descendants of $n_j^e$ and change the parities in the ancestors of $n_j^o$ up to the root of the joined tree. The parities and delays now need to be recalculated in the entire tree, which is proportional to $|\nset^e| + |\nset^o|$ (Figure \ref{fig:joinrules}c). 
\end{proof}

% \input{tikzfigs/oddevenjoin}

From Lemmas \ref{lem:nodecalc_even} and \ref{lem:nodecalc_odd}, we can define a simple rule that determines how node-trees are joined.

\begin{definition}\label{def:joinbyparity}
  Let the \emph{join by parity} rule govern how to join node-trees in the event of clusters merging. For even-joins between two even or two odd node-trees, the parent and child node-trees can be picked at random. For odd-joins between nodes $n_j^e \in \nset^e, n_j^o \in \nset^o$, always make the even node-tree a child of the odd node-tree, where $n_j^e$ is now the subroot of the subtree $\nset^e$.
\end{definition}
The \emph{join by parity} rule ensures that the parities and delays in $\nset^o$ are preserved and that only a partial calculation, equivalent to the depth-first search from node $n_j^e$, is needed. Note the concept of a \emph{partial} calculation is somewhat redundant. Using these rules for the joins of node-trees, the parity and delay calculations are never calculated on a full node-tree, except for the initial round. 

Recall from Definition \ref{def:nodeset} that the node-tree $\nset_j$ of cluster $c_j$ is stored as its root node at $c_j.n_r$, which sets the ancestry in the node-tree. In a join of two node-sets, the \emph{join by parity} rule requires to conditionally set the ancestry in the joined node-set. This can simply be done by connecting the node-trees with a new edge, and selecting the correct root node to be stored in the merged cluster (see Algorithm \ref{algo:join}). Also, due to the use of undirected edges, it is required to store the direction of the partial parity and delay calculation.

\begin{definition}
  Let us make a distinction between the \emph{final odd-join} between an odd node-tree $'\nset^o$ and an even node tree $'\nset^e$ to a joined node-tree $\nset$, and all others odd-joins that joined to $'\nset^e$ within the same round which we dub \emph{intermediate odd-joins}. 
\end{definition}

\begin{lemma}\label{lem:delaywhengrown}
  Redundant partial parity and delay calculations over even subtrees in intermediate odd-joins are prevented by applying the calculation directly before the growth of the cluster. 
\end{lemma}
\begin{proof}
  Consider the case when partial delay and parity calculations are initiated from a node $n_j^e \in \nset^e \subset \nset$ directly after the join of $\nset^e$ and $\nset^o$ to the joined node-tree $\nset$ while applying the \emph{join by parity} rule of Definition \ref{def:joinbyparity}. If there are many odd-joins (and even-joins) within the same round of growth, that at the end of round all joins to a single cluster with node-tree $\nset$, every odd-join will require the partial calculation over the even subtree. There may thus be many even subtrees where multiple partial calculations are performed within the same round before the final cluster $\nset$ is constructed. All but the final calculation will lead to the correct parities and delays in $\nset$. To circumvent any redundant calculations on the even subtrees of intermediate odd-joins, the partial calculation is suspended as much as possible, until just before a cluster is grown.
\end{proof}

Consider an example with five odd node-trees $\nset_1, ...,  \nset_5$ (Figure \ref{fig:redundantpdc}) that join to a single node-tree, where the partial calculation is applied directly after each join. The join of $\nset_1$ and $\nset_2$ to $\nset_{12}$ is an even-join and requires no partial calculation. The join of $\nset_{12}$ and $\nset_3$ is an odd-join, and we apply partial calculations in $\nset_{12}$. The join of $\nset_{123}$ and $\nset_4$ is an even-join and the join of $\nset_{1234}$ and $\nset_5$ is an odd-join, with partial calculations in $\nset_{1234}$. The earlier computation in $\nset_{12}$ is thus redundant. 

% \input{tikzfigs/partialcalculations}

The only task now is to store the subroot of the even subtree $n_j^e \in '\nset^e$ of the final odd-join, as this subroot is the starting point of the depth-first searches of the partial parity and delay calculation. For every odd-join between odd node-tree $'\m{N}^o$ and even node-tree $'\m{N}^e$ on nodes $'n_j^o, 'n_j^e$ to a cluster $c_j$, store the subroot $'n^e_j$ at the cluster as the \emph{undefined node subroot} $c_j.u$ (Algorithm \ref{algo:join}). If $c_j$ is selected for growth, and has an undefined node subroot $c_j.n_u$, we apply $\codefunc{Calcparity}(c_j.n_u)$ and $\codefunc{Calcdelay}(c_j.n_u)$ (Algorithms \ref{algo:calcparity}, \ref{algo:calcdelay}) to calculate parities and delays in undefined subtrees. We then call $\codefunc{Bloom}(c_j.n_r)$ (Algorithm \ref{algo:bloom}) to grow the cluster. 

% This data structure dynamically saves the root of the undefined part of a cluster to the root node. For any IO-join, we don't know yet whether another O-join will occur, thus each IO-join to cluster $''\nset^o$ is treated as a FO-join. For a IO-join, we thus also store the undefined subroot $u_1$ at the root $R_1=''n_R_{-1}$. If $''\nset^o$ joins with other clusters in subsequent E-join to cluster $'\nset^e$ and lastly the ``real final'' FO-join with $'\nset^o$ to $\nset^o$, we again store the undefined subroot $u_2='n_r^e$ at the new root of $R_2='n_R_{-1}$. Due to Lemma \ref{lem:nodecalc_odd}, it is certain that $u_2$ is an ancestor of $u_1$, and the PDC will traverse over all undefined regions of the set.

% \begin{theorem}\label{the:delayonce}
%   Undefined region of an odd cluster $\nset^o$ is defined as the subroot $u$ for which all children nodes including $u$ have undefined parities and delays, and is stored at root node $n^o_r$. PDC is performed for $n^o_r.u$ and its children before cluster $\nset^o$ is grown.
% \end{theorem}
% \input{pseudocodes/join}

\section{Pseudo-code}
Now we have the full description of the modification of the Union-Find decoder, which we dub the \emph{Union-Find Balanced-Bloom} decoder. Recall from Theorem \ref{the:nodepmw} that the potential matching weight is only defined if a dynamic forest of clusters is maintained. Recall also from Section \ref{sec:ufperformance} that weighted growth improves the code threshold of the Union-Find Decoder. Thus, the modification will be applied to the Dynamic-forest Bucket Union-Find decoder of Algorithm \ref{algo:dbuf}. 

In the Union-Find Balanced-Bloom decoder of Algorithm \ref{algo:ufbb}, partial parity and delay calculations are applied if a cluster $c_i$ has an undefined node subroot $c_i.n_u$, and \codefunc{Grow} (Algorithm \ref{algo:ufgrow}) is replaced with \codefunc{Ngrow} (Algorithm \ref{algo:bbgrow}). Furthermore, when iterating over the edges of the merging list $\m{L}_m$, if the vertex-tree roots of the supporting vertices do not belong to the same cluster, it either means that a new vertex is added to the cluster, or that two clusters are merged. In the first case, the new vertex is added to the node, whereas two node-trees are joined in the second case. To differentiate between these cases, we need to additionally store the node $n$ containing the vertex $v\in v.\vset$ at the vertex as $v.n$. With this data structure, two node-trees have to be joined on $v.n$ and $u.n$ if they both exist. Otherwise, the node is to be saved to the newly added vertex. 

% \input{pseudocodes/ufbb}